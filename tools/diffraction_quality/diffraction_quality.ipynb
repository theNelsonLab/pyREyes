{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reyes-tools: Parameter Tuning for Electron Diffraction Quality Determination\n",
    "\n",
    "This notebook helps you configure and optimize parameters for autonomous MicroED diffraction quality assessment. Use this tool to tune microscope-specific parameters after REyes is installed and run for the first time.\n",
    "\n",
    "**IMPORTANT**: This implementation matches the actual REyes package processing algorithm with critical uint16 overflow fixes applied.\n",
    "\n",
    "## How the Analysis Works\n",
    "\n",
    "The `DiffractionAnalyzer` uses a two-stage approach to evaluate diffraction quality:\n",
    "\n",
    "### Stage 1: Diffraction Peak Detection\n",
    "- **Gaussian Filtering**: Applies light and harsh Gaussian blurs to enhance peaks and remove background\n",
    "- **uint16 Overflow Protection**: Converts uint16 data to float64 BEFORE processing to prevent overflow\n",
    "- **Adaptive Thresholding**: Uses statistical thresholds to identify significant Diffraction Peaks\n",
    "- **Region Analysis**: Counts and localizes detected peaks while excluding the central beam\n",
    "- **Edge Masking**: Ignores 3% border regions to avoid artifacts (matches REyes implementation)\n",
    "\n",
    "### Stage 2: LQP (Lattice Quality Peaks) Assessment  \n",
    "- **Fourier Transform**: Analyzes the spatial frequency content of detected peaks\n",
    "- **LQP Detection**: Evaluates how regular/crystalline the diffraction pattern is using hardcoded FT parameters\n",
    "- **DQI Calculation**: Computes Diffraction Quality Index (DQI = LQP / Diffraction Peaks)\n",
    "- **Quality Classification**: Uses DQI threshold comparison for final classification\n",
    "\n",
    "### Quality Categories\n",
    "- **Good diffraction**: Many peaks (10+) with good lattice regularity (DQI >= good_rule)\n",
    "- **Bad diffraction**: Many peaks (10+) but poor lattice quality (DQI < good_rule)\n",
    "- **Poor diffraction**: Few peaks (3-9) but detectable pattern\n",
    "- **No diffraction**: Very few peaks (< 3) detected\n",
    "- **Grid**: Low-intensity regions (empty grid squares or carbon film)\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Parameter Tuning**: Configure analysis for different microscope setups\n",
    "- **REyes Compatibility**: Algorithms match the actual REyes implementation\n",
    "- **uint16 Overflow Protection**: Critical fix for accurate peak detection on uint16 MRC files\n",
    "- **Batch Processing**: Analyze entire directories automatically\n",
    "- **Comprehensive Visualization**: 9-panel analysis plots for each frame\n",
    "- **Statistical Reporting**: Detailed summaries and success rates\n",
    "- **Organized Output**: Results saved in structured directory hierarchy\n",
    "- **Correct Nomenclature**: Uses LQP (Lattice Quality Peaks) and DQI terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation Recomendations\n",
    "\n",
    "If you run this notebook on a computer different from where you ran REyes, ensure you have the required packages installed:\n",
    "\n",
    "```bash\n",
    "# Create a new environment (recommended)\n",
    "micromamba create -n reyes_env python=3.11\n",
    "micromamba activate reyes_env\n",
    "\n",
    "# Install required packages\n",
    "pip install hyperspy numpy matplotlib scipy scikit-image ipykernel\n",
    "\n",
    "# Note: ipykernel is lighter than full jupyter package\n",
    "# If you need full Jupyter interface, replace ipykernel with jupyter\n",
    "```\n",
    "\n",
    "## Directory Structure Expected\n",
    "\n",
    "The notebook expects your data to be organized as follows:\n",
    "```\n",
    "your_project_directory/\n",
    "├── diffraction_quality.ipynb  (this notebook)\n",
    "├── folder_1/                   (containing .mrc files)\n",
    "│   ├── image1.mrc\n",
    "│   ├── image2.mrc\n",
    "│   └── ...\n",
    "├── folder_2/                   (containing .mrc files)\n",
    "│   ├── image1.mrc\n",
    "│   └── ...\n",
    "└── snapshots/                 (special folder name)\n",
    "    ├── image1.mrc\n",
    "    └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Configuration Guide\n",
    "\n",
    "### Primary Analysis Parameters (Tunable)\n",
    "\n",
    "**`light_sigma_prim`** (default: 1)\n",
    "- Controls light Gaussian blur for spot enhancement\n",
    "- **Typical range**: 0.5-3\n",
    "- **Troubleshooting**: Increase if spots appear too sharp/noisy\n",
    "\n",
    "**`harsh_sigma_prim`** (default: 5) \n",
    "- Controls harsh Gaussian blur for background subtraction\n",
    "- **Typical range**: 3-7\n",
    "- **Troubleshooting**: Increase if background subtraction is poor\n",
    "\n",
    "**`threshold_std_prim`** (default: 5) **MOST CRITICAL**\n",
    "- Standard deviation multiplier for spot detection threshold\n",
    "- **This is the parameter you'll most likely need to tune**\n",
    "- **Typical range**: 3-8 for most data\n",
    "- **If too sensitive (noise spots)**: Increase to 7-15\n",
    "- **If missing real peaks**: Decrease to 3-4\n",
    "\n",
    "**`min_pixels_prim`** (default: 5)\n",
    "- Minimum area (in pixels) for detected spots\n",
    "- **Typical range**: 3-10\n",
    "- **High magnification**: May need to reduce to 3-4\n",
    "- **Low magnification**: May need to increase to 6-10\n",
    "\n",
    "### Quality Assessment Parameters\n",
    "\n",
    "**`good_rule`** (default: 3)\n",
    "- DQI threshold for good vs bad diffraction classification\n",
    "- **Current value provides balanced classification for most setups**\n",
    "- **More lenient**: Reduce to 2 (more \"Good\" classifications)\n",
    "- **More strict**: Increase to 4-10 (fewer \"Good\" classifications)\n",
    "\n",
    "### Fixed Parameters (Don't Change)\n",
    "\n",
    "**`exclude_center`** (Fixed: 25%)\n",
    "- Excludes central 25% to avoid counting central beam\n",
    "- Fixed in REyes implementation\n",
    "\n",
    "**FT Processing Parameters** (Fixed in REyes):\n",
    "- `harsh_sigma_ft`: 20\n",
    "- `threshold_std_ft`: 3  \n",
    "- `min_pixels_ft`: 1\n",
    "\n",
    "## Tuning Process\n",
    "\n",
    "1. **Start with defaults** (threshold_std_prim: 5, good_rule: 3)\n",
    "2. **Process a small test dataset** (20-50 different images)\n",
    "3. **Check visualizations** in `output/` directory\n",
    "4. **Adjust values as needed**\n",
    "5. **Re-run and validate** on larger dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Interpretation\n",
    "\n",
    "### Understanding the Visualization Output\n",
    "\n",
    "When you run the analysis, each frame generates a 9-panel visualization saved in `output/[folder_name]/`. Here's how to interpret the results:\n",
    "\n",
    "**Row 1 - Gaussian Filtering Steps:**\n",
    "- **Panel 1 - Original Pattern**: Raw detector image\n",
    "- **Panel 2 - Light Blur**: After light Gaussian blur for spot enhancement\n",
    "- **Panel 3 - Harsh Blur**: After harsh Gaussian blur for background subtraction\n",
    "\n",
    "**Row 2 - Diffraction Peak Detection:**\n",
    "- **Panel 4 - Difference Image**: Light - Harsh blur (should NOT show overflow artifacts!)\n",
    "- **Panel 5 - Detection Mask**: Binary image of detected regions\n",
    "- **Panel 6 - Detected Peaks**: Red circles overlaid on original\n",
    "\n",
    "**Row 3 - LQP Analysis:**\n",
    "- **Panel 7 - FT of Detection Mask**: Fourier transform for LQP analysis\n",
    "- **Panel 8 - LQP Detection Mask**: Binary image from FT analysis\n",
    "- **Panel 9 - LQP Results**: Blue circles showing detected LQP with DQI value\n",
    "\n",
    "### Critical Fix Verification\n",
    "\n",
    "**Panel 4 (Difference Image) is KEY for verifying the uint16 fix:**\n",
    "- **GOOD**: Smooth grayscale image with reasonable contrast\n",
    "- **BAD**: White/bright patches or entire image is black indicate overflow (max values ~65535)\n",
    "- **If you see overflow**: Check pixel values for images\n",
    "\n",
    "**Panel 6 (Detected Peaks) Quality Check:**\n",
    "- **Good result**: Red circles on actual Diffraction Peaks only\n",
    "- **Too sensitive**: Red circles on background noise → Increase `threshold_std_prim`\n",
    "- **Too insensitive**: Missing obvious peaks → Decrease `threshold_std_prim`\n",
    "\n",
    "### Quality Classifications\n",
    "\n",
    "**Good diffraction** (Target for data collection):\n",
    "- 10+ well-defined Diffraction Peaks\n",
    "- Regular crystalline pattern (high DQI >= good_rule)\n",
    "\n",
    "**Bad diffraction** (Many peaks but poor lattice quality):\n",
    "- 10+ Diffraction Peaks but low DQI < good_rule\n",
    "- Often indicates polycrystalline or twinned samples\n",
    "- Sometimes good patterns might be misclassified here\n",
    "\n",
    "**Poor diffraction** (Usable but limited):\n",
    "- 3-9 peaks detected\n",
    "- May indicate small crystals or partial order\n",
    "\n",
    "**No diffraction** (Empty or amorphous):\n",
    "- <3 peaks detected\n",
    "- Empty grid squares or non-crystalline material\n",
    "\n",
    "**Grid** (Empty areas):\n",
    "- Low overall intensity\n",
    "- Empty grid squares, torn areas, or thick carbon support\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "**Issue: All patterns classified as \"Bad diffraction\"**\n",
    "- **Possible cause**: `good_rule` too strict for your crystals\n",
    "- **Check**: Visually verify diffraction quality before decreasing `good_rule` from 3 to 2\n",
    "\n",
    "**Issue: Too many \"Good diffraction\" classifications**\n",
    "- **Likely cause**: `good_rule` too lenient\n",
    "- **Solution**: Increase `good_rule` from 3 to 5 or higher\n",
    "\n",
    "**Issue: Inconsistent results between similar images**\n",
    "- **Likely cause**: threshold_std_prim on the border of sensitivity\n",
    "- **Solution**: Adjust threshold_std_prim by ±1 and test consistency\n",
    "\n",
    "**Issue: Seeing overflow artifacts in Panel 4**\n",
    "- **Critical problem**: uint16 overflow fix not working\n",
    "- **Check**: Data type conversion in parse_mrc method\n",
    "- **Solution**: Ensure data.astype(np.float64) is applied before processing\n",
    "\n",
    "**Issue: Visually good diffraction patterns classified as \"Bad\"**\n",
    "- **Possible causes**: Parameter tuning needed or unexpected pixel value behavior\n",
    "- **Action required**: Check the log files for pixel value statistics and intensity distributions\n",
    "- **If inconsistencies observed**: Report details (pixel value ranges, intensity statistics, specific pattern examples) to the development team for investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "import hyperspy.api as hs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.measure import label, regionprops_table\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DiffractionResult:\n",
    "    \"\"\"Container for diffraction analysis results with updated nomenclature.\"\"\"\n",
    "    n_diffraction_spots: int  # Number of detected Diffraction Peaks (matches dif_map.py)\n",
    "    n_pattern_spots: int     # Number of pattern spots (matches dif_map.py nomenclature)\n",
    "    total_sum: float         # Total image intensity\n",
    "    dqi: float              # Diffraction Quality Index (LQP / Diffraction Peaks)\n",
    "    quality: str            # Quality classification\n",
    "\n",
    "\n",
    "class DiffractionAnalyzer:\n",
    "    \"\"\"\n",
    "    Automated electron diffraction pattern analysis for MicroED experiments.\n",
    "    \n",
    "    This class provides comprehensive analysis of electron diffraction patterns including:\n",
    "    - Automated peak detection using Gaussian filtering with uint16 overflow protection\n",
    "    - Quality classification (Good, Poor, Bad, No diffraction, Grid)\n",
    "    - LQP assessment via Fourier transform analysis\n",
    "    - DQI (Diffraction Quality Index) calculation\n",
    "    - Batch processing of MRC files\n",
    "    - Visualization and statistical reporting\n",
    "    - Pixel value statistics logging and CSV export for debugging and optimization\n",
    "    \n",
    "    IMPORTANT: This implementation matches the actual REyes package dif_map.py processing\n",
    "    with critical uint16 overflow fixes applied.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, params: Optional[Dict[str, Any]] = None):\n",
    "        \"\"\"\n",
    "        Initialize the DiffractionAnalyzer with analysis parameters.\n",
    "        \n",
    "        Args:\n",
    "            params: Dictionary of analysis parameters. If None, uses default \n",
    "                   values optimized for typical MicroED data.\n",
    "        \"\"\"\n",
    "        # Default parameters - good starting point for most microscope setups\n",
    "        self.params = {\n",
    "            # Primary analysis parameters\n",
    "            'light_sigma_prim': 1,        # Light Gaussian blur for peak enhancement\n",
    "            'harsh_sigma_prim': 5,        # Harsh Gaussian blur for background subtraction\n",
    "            'threshold_std_prim': 5,      # Std dev multiplier for peak detection threshold\n",
    "            'min_pixels_prim': 5,         # Minimum area for peak detection\n",
    "            'exclude_center': 25,         # Percentage of center to exclude from peak counting\n",
    "            \n",
    "            # Quality assessment parameters\n",
    "            'good_rule': 3,               # DQI threshold for good vs bad diffraction\n",
    "            'grid_rule': 3,               # Threshold for grid/empty region identification\n",
    "            \n",
    "            # FT processing parameters (hardcoded in REyes)\n",
    "            'harsh_sigma_ft': 20,         # Gaussian blur for FT analysis\n",
    "            'threshold_std_ft': 3,        # Threshold for pattern detection in FT\n",
    "            'min_pixels_ft': 1,           # Minimum size for FT patterns\n",
    "        }\n",
    "        \n",
    "        # Update with provided parameters if any\n",
    "        if params:\n",
    "            self.params.update(params)\n",
    "        \n",
    "        # Initialize results storage\n",
    "        self.diffraction_quality: Dict[str, DiffractionResult] = {}\n",
    "        \n",
    "        # Initialize pixel statistics storage\n",
    "        self.pixel_statistics: Dict[str, Dict[str, Any]] = {}\n",
    "        \n",
    "        # Create output directory\n",
    "        self.output_dir = Path('output')\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Setup custom logging for diffraction quality analysis\n",
    "        self.stats_log_path = self.output_dir / 'DQ_optimizer.log'\n",
    "        self.logger = self._setup_logger()\n",
    "        \n",
    "        # Counter for frame numbering in output files\n",
    "        self.frame_counter = 0\n",
    "        \n",
    "        # Track if conversion message has been logged\n",
    "        self._conversion_logged = False\n",
    "\n",
    "    def _setup_logger(self):\n",
    "        \"\"\"Setup custom logger with header information only once.\"\"\"\n",
    "        # Create custom logger\n",
    "        logger = logging.getLogger('diffraction_analyzer')\n",
    "        logger.setLevel(logging.INFO)\n",
    "        \n",
    "        # Clear existing handlers\n",
    "        for handler in logger.handlers[:]:\n",
    "            logger.removeHandler(handler)\n",
    "        \n",
    "        # Create file handler with custom formatter\n",
    "        file_handler = logging.FileHandler(self.stats_log_path, mode='w')\n",
    "        \n",
    "        # Custom formatter without timestamp for individual entries\n",
    "        formatter = logging.Formatter('%(message)s')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "        \n",
    "        # Write header information once\n",
    "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        logger.info(\"DIFFRACTION QUALITY OPTIMIZER LOG\")\n",
    "        logger.info(\"=\" * 60)\n",
    "        logger.info(f\"Analysis started: {current_time}\")\n",
    "        logger.info(\"\")\n",
    "        logger.info(\"PROCESSING PARAMETERS:\")\n",
    "        for key, value in self.params.items():\n",
    "            logger.info(f\"  {key}: {value}\")\n",
    "        logger.info(\"\")\n",
    "        logger.info(\"DIFFRACTION QUALITY ANALYSIS RESULTS:\")\n",
    "        logger.info(\"-\" * 60)\n",
    "        \n",
    "        return logger\n",
    "\n",
    "    def log_pixel_statistics_csv(self, data: np.ndarray, light_blur_data: np.ndarray, \n",
    "                                harsh_blur_data: np.ndarray, difference_data: np.ndarray, \n",
    "                                folder_name: Optional[str], file_name: str):\n",
    "        \"\"\"\n",
    "        Log pixel statistics for all image processing steps to a CSV file.\n",
    "        This matches the functionality from the _fixed version.\n",
    "        \n",
    "        Args:\n",
    "            data: Original image data\n",
    "            light_blur_data: Light Gaussian blur result\n",
    "            harsh_blur_data: Harsh Gaussian blur result  \n",
    "            difference_data: Difference image (light - harsh)\n",
    "            folder_name: Name of containing folder\n",
    "            file_name: Name of MRC file\n",
    "        \"\"\"\n",
    "        # Create log directory if it doesn't exist\n",
    "        log_dir = self.output_dir / folder_name if folder_name else self.output_dir\n",
    "        log_dir.mkdir(exist_ok=True)\n",
    "        csv_file = log_dir / 'pixel_statistics_detailed.csv'\n",
    "        \n",
    "        # Calculate statistics for each image\n",
    "        images = {\n",
    "            'original_pattern': data,\n",
    "            'light_blur': light_blur_data,\n",
    "            'harsh_blur': harsh_blur_data,\n",
    "            'difference_image': difference_data\n",
    "        }\n",
    "        \n",
    "        # Check if file exists to determine if we need header\n",
    "        file_exists = csv_file.exists()\n",
    "        \n",
    "        with open(csv_file, 'a', newline='') as csvfile:\n",
    "            fieldnames = ['file_name', 'image_type', 'min_pixel', 'max_pixel', 'mean_pixel', 'std_pixel']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            \n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "            \n",
    "            # Write statistics for each image type\n",
    "            for img_name, img_data in images.items():\n",
    "                writer.writerow({\n",
    "                    'file_name': file_name,\n",
    "                    'image_type': img_name,\n",
    "                    'min_pixel': float(np.min(img_data)),\n",
    "                    'max_pixel': float(np.max(img_data)),\n",
    "                    'mean_pixel': float(np.mean(img_data)),\n",
    "                    'std_pixel': float(np.std(img_data))\n",
    "                })\n",
    "\n",
    "    def log_pixel_statistics(self, file_name: str, data: np.ndarray, \n",
    "                           light_blur_data: np.ndarray, harsh_blur_data: np.ndarray, \n",
    "                           difference_data: np.ndarray, threshold_value: float,\n",
    "                           n_diffraction_spots: int = None, n_pattern_spots: int = None, \n",
    "                           dqi: float = None, quality: str = None, total_sum: float = None):\n",
    "        \"\"\"\n",
    "        Log comprehensive pixel value statistics and analysis results for debugging and optimization.\n",
    "        \"\"\"\n",
    "        stats = {\n",
    "            'file_name': file_name,\n",
    "            'original_dtype': str(data.dtype),\n",
    "            'original_range': [float(np.min(data)), float(np.max(data))],\n",
    "            'original_mean': float(np.mean(data)),\n",
    "            'original_std': float(np.std(data)),\n",
    "            'light_blur_range': [float(np.min(light_blur_data)), float(np.max(light_blur_data))],\n",
    "            'harsh_blur_range': [float(np.min(harsh_blur_data)), float(np.max(harsh_blur_data))],\n",
    "            'difference_range': [float(np.min(difference_data)), float(np.max(difference_data))],\n",
    "            'difference_mean': float(np.mean(difference_data)),\n",
    "            'difference_std': float(np.std(difference_data)),\n",
    "            'threshold_value': float(threshold_value),\n",
    "            'pixels_above_threshold': int(np.sum(difference_data > threshold_value)),\n",
    "            'total_pixels': int(data.size)\n",
    "        }\n",
    "        \n",
    "        # Store statistics\n",
    "        self.pixel_statistics[file_name] = stats\n",
    "        \n",
    "        # Log to file (no timestamps, clean format)\n",
    "        self.logger.info(f\"ANALYSIS RESULTS for {file_name}\")\n",
    "        \n",
    "        # Log analysis results if provided\n",
    "        if total_sum is not None:\n",
    "            self.logger.info(f\"  Total intensity: {total_sum:.0f}\")\n",
    "        if n_diffraction_spots is not None:\n",
    "            self.logger.info(f\"  Diffraction Peaks: {n_diffraction_spots}\")\n",
    "        if n_pattern_spots is not None:\n",
    "            self.logger.info(f\"  LQP: {n_pattern_spots}\")\n",
    "        if dqi is not None:\n",
    "            self.logger.info(f\"  DQI: {dqi:.3f}\")\n",
    "        if quality is not None:\n",
    "            self.logger.info(f\"  Classification: {quality}\")\n",
    "        \n",
    "        # Log pixel statistics\n",
    "        self.logger.info(f\"  Original data: dtype={stats['original_dtype']}, \"\n",
    "                        f\"range=[{stats['original_range'][0]:.1f}, {stats['original_range'][1]:.1f}], \"\n",
    "                        f\"mean={stats['original_mean']:.1f}, std={stats['original_std']:.1f}\")\n",
    "        self.logger.info(f\"  Light blur range: [{stats['light_blur_range'][0]:.1f}, {stats['light_blur_range'][1]:.1f}]\")\n",
    "        self.logger.info(f\"  Harsh blur range: [{stats['harsh_blur_range'][0]:.1f}, {stats['harsh_blur_range'][1]:.1f}]\")\n",
    "        self.logger.info(f\"  Difference image: range=[{stats['difference_range'][0]:.1f}, {stats['difference_range'][1]:.1f}], \"\n",
    "                        f\"mean={stats['difference_mean']:.2f}, std={stats['difference_std']:.2f}\")\n",
    "        self.logger.info(f\"  Threshold: {stats['threshold_value']:.2f}\")\n",
    "        self.logger.info(f\"  Pixels above threshold: {stats['pixels_above_threshold']}/{stats['total_pixels']} \"\n",
    "                        f\"({100*stats['pixels_above_threshold']/stats['total_pixels']:.1f}%)\")\n",
    "        \n",
    "        # Check for potential overflow issues\n",
    "        if stats['original_dtype'] in ['uint16', 'uint8', 'uint32']:\n",
    "            if stats['original_dtype'] == 'uint16' and stats['difference_range'][1] > 60000:\n",
    "                self.logger.info(f\"  WARNING: HIGH DIFFERENCE VALUES detected! Max difference: {stats['difference_range'][1]:.1f}\")\n",
    "                self.logger.info(f\"  WARNING: This suggests uint16 overflow may have occurred\")\n",
    "            elif stats['original_dtype'] == 'uint8' and stats['difference_range'][1] > 240:\n",
    "                self.logger.info(f\"  WARNING: HIGH DIFFERENCE VALUES detected! Max difference: {stats['difference_range'][1]:.1f}\")\n",
    "        \n",
    "        self.logger.info(\"  \" + \"-\" * 60)\n",
    "\n",
    "    def parse_mrc(self, mrc_file: str) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Load MRC file using HyperSpy with uint16 overflow protection.\n",
    "        Matches dif_map.py parse_mrc method exactly.\n",
    "        \n",
    "        Args:\n",
    "            mrc_file: Path to the MRC file\n",
    "            \n",
    "        Returns:\n",
    "            Image data array as float64 to prevent overflow\n",
    "        \"\"\"\n",
    "        signal = hs.load(mrc_file)\n",
    "        data = signal.data\n",
    "        \n",
    "        # CRITICAL FIX: Convert unsigned integer data to float64 early to prevent overflow\n",
    "        if data.dtype in [np.uint8, np.uint16, np.uint32]:\n",
    "            if not self._conversion_logged:\n",
    "                print(f\"Converting {data.dtype} to float64 to prevent overflow\")\n",
    "                self._conversion_logged = True\n",
    "            data = data.astype(np.float64)\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def create_binary_image(self, data: np.ndarray, light_sigma: float, \n",
    "                          harsh_sigma: float, threshold_std: float, \n",
    "                          ft_done: bool = False) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Create binary image for peak detection using Gaussian filtering and thresholding.\n",
    "        Matches REyes ImageProcessor.create_binary_image() method with overflow protection.\n",
    "        \"\"\"\n",
    "        # CRITICAL FIX: Convert uint16 to float64 to prevent overflow\n",
    "        if data.dtype in [np.uint8, np.uint16, np.uint32]:\n",
    "            data = data.astype(np.float64)\n",
    "        \n",
    "        if ft_done:\n",
    "            # For FT data, use hardcoded values as in REyes\n",
    "            harsh_blur_data = gaussian_filter(data, sigma=20)\n",
    "            difference_data = data - harsh_blur_data\n",
    "            threshold_value = np.mean(difference_data) + (3 * np.std(difference_data))\n",
    "        else:\n",
    "            # Standard processing: subtract harsh blur from light blur\n",
    "            light_blur_data = gaussian_filter(data, sigma=light_sigma)\n",
    "            harsh_blur_data = gaussian_filter(data, sigma=harsh_sigma)\n",
    "            difference_data = light_blur_data - harsh_blur_data\n",
    "            threshold_value = np.mean(difference_data) + (threshold_std * np.std(difference_data))\n",
    "\n",
    "        binary_image = difference_data > threshold_value\n",
    "        \n",
    "        # Mask 3% on all four sides (matches REyes)\n",
    "        mask_size_x = int(binary_image.shape[1] * 0.03)\n",
    "        mask_size_y = int(binary_image.shape[0] * 0.03)\n",
    "        \n",
    "        binary_image[:, :mask_size_x] = False\n",
    "        binary_image[:, -mask_size_x:] = False\n",
    "        binary_image[:mask_size_y, :] = False\n",
    "        binary_image[-mask_size_y:, :] = False\n",
    "        \n",
    "        return binary_image\n",
    "\n",
    "    def get_binary_ft(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate Fourier transform magnitude (matches REyes implementation).\n",
    "        \"\"\"\n",
    "        ft_data = np.fft.fftshift(np.fft.fft2(data))\n",
    "        ft_magnitude = np.log(np.abs(ft_data) + 1)\n",
    "        return ft_magnitude\n",
    "\n",
    "    def get_centroids(self, binary_image: np.ndarray, min_pixels: int, \n",
    "                     exclude_center: Optional[float] = None, \n",
    "                     ft_done: bool = False) -> Tuple[List[Tuple[float, float]], int]:\n",
    "        \"\"\"\n",
    "        Extract centroids of detected regions from binary image.\n",
    "        Matches REyes ImageProcessor.get_centroids() method exactly.\n",
    "        \"\"\"\n",
    "        labeled_array = label(binary_image)\n",
    "        properties = regionprops_table(labeled_array, properties=('centroid', 'area'))\n",
    "        \n",
    "        # Use min_pixels=1 for FT patterns, config value otherwise (matches dif_map.py)\n",
    "        min_pixels_to_use = 1 if ft_done else min_pixels\n",
    "        \n",
    "        # Filter by minimum area\n",
    "        centroids = [(x, y) for x, y, area in zip(properties['centroid-0'], \n",
    "                                                 properties['centroid-1'],\n",
    "                                                 properties['area']) \n",
    "                    if area >= min_pixels_to_use]\n",
    "        \n",
    "        # For diffraction analysis, exclude central region (avoid central beam)\n",
    "        if not ft_done and exclude_center is not None:\n",
    "            image_shape = binary_image.shape\n",
    "            center_x, center_y = image_shape[1] // 2, image_shape[0] // 2\n",
    "            min_distance = min(center_x, center_y)\n",
    "            exclude_radius = (exclude_center / 100) * min_distance\n",
    "            \n",
    "            filtered_centroids = [\n",
    "                centroid for centroid in centroids\n",
    "                if not (center_x - exclude_radius < centroid[1] < center_x + exclude_radius and\n",
    "                        center_y - exclude_radius < centroid[0] < center_y + exclude_radius)\n",
    "            ]\n",
    "        else:\n",
    "            filtered_centroids = centroids\n",
    "        \n",
    "        return filtered_centroids, len(filtered_centroids)\n",
    "\n",
    "    def _classify_diffraction(self, n_dif_spots: int, n_pat_spots: int) -> str:\n",
    "        \"\"\"\n",
    "        Classify diffraction quality based on peak counts and DQI.\n",
    "        Matches REyes DiffractionAnalyzer._classify_diffraction() method exactly.\n",
    "        \"\"\"\n",
    "        if n_dif_spots < 3:\n",
    "            return 'No diffraction'\n",
    "        elif n_dif_spots < 10:\n",
    "            return 'Poor diffraction'\n",
    "        elif self.params['good_rule'] * n_dif_spots > n_pat_spots:\n",
    "            # DQI (n_pat_spots/n_dif_spots) is below good_rule threshold\n",
    "            return 'Bad diffraction'\n",
    "        else:\n",
    "            # DQI (n_pat_spots/n_dif_spots) meets good_rule threshold\n",
    "            return 'Good diffraction'\n",
    "\n",
    "    def process_file(self, file_path: str, visualize: bool = True, \n",
    "                    folder_name: Optional[str] = None) -> Optional[DiffractionResult]:\n",
    "        \"\"\"\n",
    "        Process a single MRC file for diffraction quality analysis.\n",
    "        Matches dif_map.py process_mrc_file method logic exactly.\n",
    "        \"\"\"\n",
    "        file_name = os.path.basename(file_path)\n",
    "        print(f\"Processing: {file_name}\")\n",
    "\n",
    "        try:\n",
    "            # Load and analyze image data with overflow protection\n",
    "            data = self.parse_mrc(file_path)\n",
    "            total_sum = np.sum(data)\n",
    "\n",
    "            # Generate Gaussian blurred images for analysis\n",
    "            light_blur_data = gaussian_filter(data, sigma=self.params['light_sigma_prim'])\n",
    "            harsh_blur_data = gaussian_filter(data, sigma=self.params['harsh_sigma_prim'])\n",
    "            difference_data = light_blur_data - harsh_blur_data\n",
    "            \n",
    "            # Calculate threshold for pixel statistics logging\n",
    "            threshold_value = np.mean(difference_data) + (self.params['threshold_std_prim'] * np.std(difference_data))\n",
    "            \n",
    "            # Log pixel statistics to CSV (matches _fixed version functionality)\n",
    "            self.log_pixel_statistics_csv(data, light_blur_data, harsh_blur_data, \n",
    "                                         difference_data, folder_name, file_name)\n",
    "\n",
    "            # Create primary binary image and detect Diffraction Peaks\n",
    "            primary_binary_image = self.create_binary_image(\n",
    "                data, \n",
    "                self.params['light_sigma_prim'],\n",
    "                self.params['harsh_sigma_prim'],\n",
    "                self.params['threshold_std_prim'],\n",
    "                ft_done=False\n",
    "            )\n",
    "\n",
    "            primary_centroids, n_dif_spots = self.get_centroids(\n",
    "                primary_binary_image,\n",
    "                self.params['min_pixels_prim'],\n",
    "                exclude_center=25,\n",
    "                ft_done=False\n",
    "            )\n",
    "\n",
    "            # Process FT pattern for LQP detection (matches dif_map.py exactly)\n",
    "            ft_binary_image = self.get_binary_ft(primary_binary_image)\n",
    "            secondary_binary_image = self.create_binary_image(\n",
    "                ft_binary_image,\n",
    "                None,  # Not used for FT processing\n",
    "                self.params['harsh_sigma_ft'],\n",
    "                self.params['threshold_std_ft'],\n",
    "                ft_done=True\n",
    "            )\n",
    "\n",
    "            secondary_centroids, n_pat_spots = self.get_centroids(\n",
    "                secondary_binary_image,\n",
    "                self.params['min_pixels_ft'],\n",
    "                exclude_center=None,\n",
    "                ft_done=True\n",
    "            )\n",
    "\n",
    "            # Calculate Diffraction Quality Index (DQI)\n",
    "            dqi = n_pat_spots / n_dif_spots if n_dif_spots > 0 else 0\n",
    "\n",
    "            # Classify diffraction quality using DQI (matches dif_map.py exactly)\n",
    "            quality = self._classify_diffraction(n_dif_spots, n_pat_spots)\n",
    "\n",
    "            # Log pixel statistics and analysis results for debugging and optimization\n",
    "            self.log_pixel_statistics(file_name, data, light_blur_data, harsh_blur_data, \n",
    "                                    difference_data, threshold_value, n_dif_spots, n_pat_spots, \n",
    "                                    dqi, quality, total_sum)\n",
    "\n",
    "            # Create result object (matches dif_map.py DiffractionResult)\n",
    "            result = DiffractionResult(\n",
    "                n_diffraction_spots=n_dif_spots,\n",
    "                n_pattern_spots=n_pat_spots,\n",
    "                total_sum=total_sum,\n",
    "                dqi=dqi,\n",
    "                quality=quality\n",
    "            )\n",
    "\n",
    "            # Store results\n",
    "            self.diffraction_quality[file_name] = result\n",
    "\n",
    "            # Generate visualization if requested\n",
    "            if visualize:\n",
    "                self.visualize_results(\n",
    "                    data, \n",
    "                    primary_binary_image, \n",
    "                    ft_binary_image,\n",
    "                    secondary_binary_image,\n",
    "                    primary_centroids, \n",
    "                    secondary_centroids,\n",
    "                    folder_name,\n",
    "                    file_name,\n",
    "                    light_blur_data,\n",
    "                    harsh_blur_data,\n",
    "                    difference_data\n",
    "                )\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def visualize_results(self, data, primary_binary, ft_image, secondary_binary, \n",
    "                         primary_centroids=None, secondary_centroids=None, \n",
    "                         folder_name=None, file_name=None,\n",
    "                         light_blur_data=None, harsh_blur_data=None, \n",
    "                         difference_data=None):\n",
    "        \"\"\"\n",
    "        Create comprehensive 3x3 visualization of analysis results.\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(15, 15))\n",
    "        \n",
    "        # Generate informative title\n",
    "        n_dif = len(primary_centroids) if primary_centroids else 0\n",
    "        n_pat = len(secondary_centroids) if secondary_centroids else 0\n",
    "        dqi = n_pat / n_dif if n_dif > 0 else 0\n",
    "        quality = self._classify_diffraction(n_dif, n_pat)\n",
    "        \n",
    "        title_line1 = f'Diffraction Peaks: {n_dif} | LQP: {n_pat} | DQI: {dqi:.3f} | Assessment: {quality}'\n",
    "        title_line2 = f'File: {file_name}' if file_name else ''\n",
    "        \n",
    "        plt.suptitle(\n",
    "            f'{title_line1}\\n{title_line2}',\n",
    "            fontsize=14, y=0.95\n",
    "        )\n",
    "        \n",
    "        # Create 3x3 subplot grid\n",
    "        gs = plt.GridSpec(3, 3, figure=fig, hspace=0.3, wspace=0.2)\n",
    "        \n",
    "        # Generate Gaussian smoothed images if not provided\n",
    "        if light_blur_data is None:\n",
    "            light_blur_data = gaussian_filter(data, sigma=self.params['light_sigma_prim'])\n",
    "        if harsh_blur_data is None:\n",
    "            harsh_blur_data = gaussian_filter(data, sigma=self.params['harsh_sigma_prim'])\n",
    "        if difference_data is None:\n",
    "            difference_data = light_blur_data - harsh_blur_data\n",
    "        \n",
    "        # Set consistent intensity scaling\n",
    "        vmin, vmax = np.percentile(data, 1), np.percentile(data, 99)\n",
    "        \n",
    "        # Row 1: Gaussian Filtering Steps\n",
    "        \n",
    "        # 1. Original diffraction pattern\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        ax1.imshow(data, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        ax1.set_title('Original Pattern', fontsize=12)\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # 2. After light sigma Gaussian blur\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        ax2.imshow(light_blur_data, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        ax2.set_title(f'Light Blur (sigma={self.params[\"light_sigma_prim\"]})', fontsize=12)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # 3. After harsh sigma Gaussian blur\n",
    "        ax3 = fig.add_subplot(gs[0, 2])\n",
    "        ax3.imshow(harsh_blur_data, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        ax3.set_title(f'Harsh Blur (sigma={self.params[\"harsh_sigma_prim\"]})', fontsize=12)\n",
    "        ax3.axis('off')\n",
    "        \n",
    "        # Row 2: Diffraction Peak Detection Process\n",
    "        \n",
    "        # 4. Difference image (light - harsh)\n",
    "        ax4 = fig.add_subplot(gs[1, 0])\n",
    "        diff_vmin, diff_vmax = np.percentile(difference_data, 5), np.percentile(difference_data, 95)\n",
    "        ax4.imshow(difference_data, cmap='gray', vmin=diff_vmin, vmax=diff_vmax)\n",
    "        ax4.set_title('Difference Image\\n(Light - Harsh)', fontsize=12)\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        # 5. Binary mask from diffraction peak detection\n",
    "        ax5 = fig.add_subplot(gs[1, 1])\n",
    "        ax5.imshow(primary_binary, cmap='gray')\n",
    "        ax5.set_title(f'Diffraction Peak Detection\\n(threshold={self.params[\"threshold_std_prim\"]}sigma)', fontsize=12)\n",
    "        ax5.axis('off')\n",
    "        \n",
    "        # 6. Detected Diffraction Peaks overlaid on original\n",
    "        ax6 = fig.add_subplot(gs[1, 2])\n",
    "        ax6.imshow(data, cmap='gray', vmin=vmin, vmax=vmax)\n",
    "        if primary_centroids:\n",
    "            ax6.scatter(\n",
    "                [c[1] for c in primary_centroids], [c[0] for c in primary_centroids],\n",
    "                color='red', s=20, marker='o', facecolors='none', edgecolors='red', linewidth=1.5\n",
    "            )\n",
    "        ax6.set_title(f'Detected Diffraction Peaks\\n({n_dif} peaks)', fontsize=12)\n",
    "        ax6.axis('off')\n",
    "        \n",
    "        # Row 3: LQP Analysis\n",
    "        \n",
    "        # 7. Fourier transform for LQP analysis\n",
    "        ax7 = fig.add_subplot(gs[2, 0])\n",
    "        ax7.imshow(ft_image, cmap='gray')\n",
    "        ax7.set_title('FT of Diffraction Peak\\nDetection Mask', fontsize=12)\n",
    "        ax7.axis('off')\n",
    "        \n",
    "        # 8. Binary mask from FT analysis for LQP detection\n",
    "        ax8 = fig.add_subplot(gs[2, 1])\n",
    "        ax8.imshow(secondary_binary, cmap='gray')\n",
    "        ax8.set_title('LQP Detection Mask', fontsize=12)\n",
    "        ax8.axis('off')\n",
    "        \n",
    "        # 9. LQP with DQI\n",
    "        ax9 = fig.add_subplot(gs[2, 2])\n",
    "        ax9.imshow(secondary_binary, cmap='gray')\n",
    "        if secondary_centroids:\n",
    "            ax9.scatter(\n",
    "                [c[1] for c in secondary_centroids], [c[0] for c in secondary_centroids],\n",
    "                color='blue', s=20, marker='o', facecolors='none', edgecolors='blue', linewidth=1.5\n",
    "            )\n",
    "        ax9.set_title(f'LQP: {n_pat} | DQI: {dqi:.3f}', fontsize=12)\n",
    "        ax9.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save with organized directory structure\n",
    "        if folder_name:\n",
    "            save_dir = self.output_dir / folder_name\n",
    "            save_dir.mkdir(exist_ok=True)\n",
    "            save_path = save_dir / f'diffraction_analysis_frame_{self.frame_counter:03d}.png'\n",
    "        else:\n",
    "            save_path = self.output_dir / f'diffraction_analysis_frame_{self.frame_counter:03d}.png'\n",
    "        \n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        self.frame_counter += 1\n",
    "        plt.close()\n",
    "\n",
    "    def update_diffraction_quality(self):\n",
    "        \"\"\"\n",
    "        Post-process results to identify grid/empty regions based on intensity.\n",
    "        Matches dif_map.py update_diffraction_quality method exactly.\n",
    "        \"\"\"\n",
    "        sums = [result.total_sum for result in self.diffraction_quality.values()]\n",
    "        if not sums:\n",
    "            return\n",
    "            \n",
    "        mean_sum = np.mean(sums)\n",
    "        threshold = mean_sum / self.params['grid_rule']\n",
    "\n",
    "        # Reclassify low-intensity regions as grid\n",
    "        for file_name, result in self.diffraction_quality.items():\n",
    "            if result.total_sum < threshold:\n",
    "                updated_result = DiffractionResult(\n",
    "                    n_diffraction_spots=0,\n",
    "                    n_pattern_spots=0,\n",
    "                    total_sum=result.total_sum,\n",
    "                    dqi=0,\n",
    "                    quality='Grid'\n",
    "                )\n",
    "                self.diffraction_quality[file_name] = updated_result\n",
    "\n",
    "    def print_summary_statistics(self):\n",
    "        \"\"\"Print comprehensive summary statistics.\"\"\"\n",
    "        if not self.diffraction_quality:\n",
    "            print(\"No results to summarize.\")\n",
    "            return\n",
    "\n",
    "        # Count occurrences of each quality category\n",
    "        quality_counts = {\n",
    "            'No diffraction': 0,\n",
    "            'Poor diffraction': 0,\n",
    "            'Good diffraction': 0,\n",
    "            'Bad diffraction': 0,\n",
    "            'Grid': 0\n",
    "        }\n",
    "\n",
    "        for result in self.diffraction_quality.values():\n",
    "            quality = result.quality\n",
    "            if quality in quality_counts:\n",
    "                quality_counts[quality] += 1\n",
    "\n",
    "        total = sum(quality_counts.values())\n",
    "\n",
    "        # Print summary\n",
    "        print(\"\\nDIFFRACTION ANALYSIS SUMMARY\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        for quality, count in quality_counts.items():\n",
    "            percentage = (count / total * 100) if total > 0 else 0\n",
    "            print(f\"{quality:>18}: {count:>3} ({percentage:5.1f}%)\")\n",
    "        \n",
    "        print(f\"{'Total analyzed':>18}: {total:>3}\")\n",
    "        \n",
    "        # Calculate useful metrics\n",
    "        if total > 0:\n",
    "            usable = quality_counts['Good diffraction'] + quality_counts['Poor diffraction']\n",
    "            usable_pct = (usable / total * 100)\n",
    "            print(f\"\\nUsable patterns: {usable}/{total} ({usable_pct:.1f}%)\")\n",
    "            \n",
    "            # Print average DQI information\n",
    "            avg_dqi = np.mean([r.dqi for r in self.diffraction_quality.values() if r.dqi > 0])\n",
    "            if not np.isnan(avg_dqi):\n",
    "                print(f\"Average DQI: {avg_dqi:.3f}\")\n",
    "\n",
    "    def process_directory(self, directory_path: str, visualize: bool = True, \n",
    "                         max_files: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Process all MRC files in a directory.\n",
    "        \"\"\"\n",
    "        self.frame_counter = 0\n",
    "        folder_name = os.path.basename(directory_path)\n",
    "        \n",
    "        directory_path = Path(directory_path)\n",
    "        if not directory_path.exists():\n",
    "            print(f\"Directory not found: {directory_path}\")\n",
    "            return self.diffraction_quality\n",
    "\n",
    "        mrc_files = list(directory_path.glob(\"*.mrc\"))\n",
    "        \n",
    "        if not mrc_files:\n",
    "            print(f\"No MRC files found in {directory_path}\")\n",
    "            return self.diffraction_quality\n",
    "\n",
    "        # Limit number of files if specified\n",
    "        if max_files is not None and len(mrc_files) > max_files:\n",
    "            mrc_files = sorted(mrc_files)[:max_files]\n",
    "            print(f\"Processing first {max_files} of {len(list(directory_path.glob('*.mrc')))} files\")\n",
    "        else:\n",
    "            mrc_files = sorted(mrc_files)\n",
    "            print(f\"Processing {len(mrc_files)} files in {folder_name}\")\n",
    "        \n",
    "        # Process each file\n",
    "        processed_count = 0\n",
    "        for mrc_file in mrc_files:\n",
    "            result = self.process_file(str(mrc_file), visualize, folder_name)\n",
    "            if result is not None:\n",
    "                processed_count += 1\n",
    "\n",
    "        # Post-process and generate summary (matches dif_map.py)\n",
    "        self.update_diffraction_quality()\n",
    "        print(f\"Completed processing {processed_count} files\")\n",
    "        self.print_summary_statistics()\n",
    "        \n",
    "        print(f\"\\nFILES CREATED:\")\n",
    "        print(f\"  * output/{folder_name}/pixel_statistics_detailed.csv - Detailed pixel stats for each processing step\")\n",
    "        print(f\"  * output/DQ_optimizer.log - Complete diffraction quality analysis log\")\n",
    "        \n",
    "        return self.diffraction_quality\n",
    "\n",
    "print(\"DiffractionAnalyzer class loaded with pixel statistics logging and CSV export functionality\")\n",
    "print(\"This implementation matches dif_map.py logic exactly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure analysis parameters\n",
    "# These default values are a good starting point for most microscope setups\n",
    "\n",
    "params = {\n",
    "    # PRIMARY ANALYSIS PARAMETERS (Most likely to need tuning)\n",
    "    'light_sigma_prim': 1,        # Spot enhancement\n",
    "    'harsh_sigma_prim': 5,        # Background subtraction\n",
    "    'threshold_std_prim': 6,      # CRITICAL: Spot detection sensitivity\n",
    "    'min_pixels_prim': 5,         # Minimum spot size\n",
    "    \n",
    "    # QUALITY ASSESSMENT PARAMETERS\n",
    "    'good_rule': 3,               # DQI threshold for quality classification\n",
    "    'grid_rule': 3,               # Grid detection\n",
    "    \n",
    "    # ADVANCED PARAMETERS (fixed - don't change)\n",
    "    'exclude_center': 25,         # Central beam exclusion\n",
    "    'harsh_sigma_ft': 20,         # FT processing\n",
    "    'threshold_std_ft': 3,        # FT threshold\n",
    "    'min_pixels_ft': 1,           # FT min pixels\n",
    "}\n",
    "\n",
    "print(\"PARAMETER CONFIGURATION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for key, value in params.items():\n",
    "    if key in ['threshold_std_prim', 'good_rule']:\n",
    "        print(f\"{key:>20}: {value:>3} <- KEY PARAMETER\")\n",
    "    else:\n",
    "        print(f\"{key:>20}: {value:>3}\")\n",
    "\n",
    "print(\"\\nCOMMON ADJUSTMENTS:\")\n",
    "print(\"1. NOISY DATA: increase threshold_std_prim to 6-8\")\n",
    "print(\"2. WEAK DIFFRACTION: decrease threshold_std_prim to 3-4\")\n",
    "print(\"3. STRICT QUALITY: increase good_rule to 4-5\")\n",
    "print(\"4. LENIENT QUALITY: decrease good_rule to 2\")\n",
    "\n",
    "# Initialize the analyzer\n",
    "analyzer = DiffractionAnalyzer(params)\n",
    "print(\"\\nAnalyzer initialized with default parameters\")\n",
    "print(\"Ready to process MRC files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = DiffractionAnalyzer(params)\n",
    "\n",
    "# Process folders\n",
    "current_path = os.getcwd()\n",
    "for folder in os.listdir(current_path):\n",
    "    if os.path.isdir(folder) and (folder == 'snapshots' or '_' in folder):\n",
    "        print(f\"\\nProcessing folder: {folder}\")\n",
    "        results = analyzer.process_directory(folder, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reyes_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
